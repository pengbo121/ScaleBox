{
  "HumanEval": {
    "datasetType": "HumanEvalDataset",
    "datasets": [
      {
        "id": "humaneval_python",
        "dataset": "humaneval_python",
        "huggingFace": {
          "id": "openai/openai_humaneval",
          "split": "test"
        }
      }
    ],
    "infer_parameters": [{
      "model_path": "/mnt/data1/wangpengbo2025/.cache/modelscope/hub/models/LLM-Research/Meta-Llama-3.1-8B-Instruct",
      "output_dir": "res/humaneval_Llama-3.1-8B-Instruct",
      "endpoint": "http://10.0.1.3:8080/common_evaluate_batch",
      "prompt_type": "llama-3-instruct",
      "temperature": 0,
      "top_p": 0.8,
      "top_k": 0,
      "min_p": 0,
      "max_completion_tokens": 32768,
      "n_sample": 1,
      "stop_token": "<|im_end|>",
      "num_gpus_total": 1,
      "num_gpus_per_model": 1,
      "reasoning_model": false
    },
    {
      "model_path": "/mnt/data2/hf_models/llama3-8B-Instruct",
      "output_dir": "res/humaneval_llama3-8B-Instruct",
      "endpoint": "http://10.0.1.3:8080/common_evaluate_batch",
      "prompt_type": "llama-3-instruct",
      "temperature": 0,
      "top_p": 0.8,
      "top_k": 0,
      "min_p": 0,
      "max_completion_tokens": 32768,
      "n_sample": 1,
      "stop_token": "<|im_end|>",
      "num_gpus_total": 1,
      "num_gpus_per_model": 1,
      "reasoning_model": false
    }]
  },
  "MBPP": {
    "datasetType": "MBPPDataset",
    "datasets": [
      {
        "id": "mbpp",
        "dataset": "mbpp",
        "huggingFace": {
          "id": "laylarsssss/FusedMBPP",
          "split": "test"
        }
      }
    ],
    "infer_parameters": [{
      "model_path": "/mnt/data1/wangpengbo2025/.cache/modelscope/hub/models/LLM-Research/Meta-Llama-3.1-8B-Instruct",
      "output_dir": "res/humaneval_Llama-3.1-8B-Instruct",
      "endpoint": "http://10.0.1.3:8080/common_evaluate_batch",
      "prompt_type": "llama-3-instruct",
      "temperature": 0,
      "top_p": 0.8,
      "top_k": 0,
      "min_p": 0,
      "max_completion_tokens": 32768,
      "n_sample": 1,
      "stop_token": "<|im_end|>",
      "num_gpus_total": 1,
      "num_gpus_per_model": 1,
      "reasoning_model": false
    },
    {
      "model_path": "/mnt/data2/hf_models/llama3-8B-Instruct",
      "output_dir": "res/humaneval_llama3-8B-Instruct",
      "endpoint": "http://10.0.1.3:8080/common_evaluate_batch",
      "prompt_type": "llama-3-instruct",
      "temperature": 0,
      "top_p": 0.8,
      "top_k": 0,
      "min_p": 0,
      "max_completion_tokens": 32768,
      "n_sample": 1,
      "stop_token": "<|im_end|>",
      "num_gpus_total": 1,
      "num_gpus_per_model": 1,
      "reasoning_model": false
    }]
  },
  "LiveCodeBench": {
    "datasetType": "LiveCodeBenchDataset",
    "datasets": [
      {
        "id": "livecodebench",
        "dataset": "livecodebench",
        "version": "v5",
        "begin_date": "2024-08-01",
        "end_date": "2025-02-01"
      }
    ],
    "infer_parameters": [{
      "model_path": "/mnt/data1/hf_models/DeepSeek-R1-Distill-Qwen-1.5B",
      "output_dir": "res/lcb_DeepSeek-R1-Distill-Qwen-1.5B",
      "endpoint": "http://10.0.1.3:8080/common_evaluate_batch",
      "prompt_type": "deepseek",
      "temperature": 0.6,
      "top_p": 0.95,
      "top_k": 20,
      "min_p": 0.0,
      "max_completion_tokens": 32768,
      "n_sample": 4,
      "stop_token": "<｜end▁of▁sentence｜>",
      "num_gpus_total": 8,
      "num_gpus_per_model": 1,
      "reasoning_model": true
    },
    {
      "model_path": "/mnt/data1/hf_models/Qwen3-4B",
      "output_dir": "res/lcb_Qwen3-4B",
      "endpoint": "http://10.0.1.3:8080/common_evaluate_batch",
      "prompt_type": "chatml_qwen3",
      "temperature": 0.6,
      "top_p": 0.95,
      "top_k": 20,
      "min_p": 0.0,
      "max_completion_tokens": 32768,
      "n_sample": 4,
      "stop_token": "<|im_end|>",
      "num_gpus_total": 8,
      "num_gpus_per_model": 1,
      "reasoning_model": true
    }]
  }
}
  