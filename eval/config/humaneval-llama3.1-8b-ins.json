{
  "HumanEval": {
    "datasetType": "HumanEvalDataset",
    "datasets": [
      {
        "id": "humaneval_python",
        "dataset": "humaneval_python",
        "huggingFace": {
          "id": "openai/openai_humaneval",
          "split": "test"
        }
      }
    ],
    "infer_parameters": [{
      "model_path": "/mnt/data1/wangpengbo2025/.cache/modelscope/hub/models/LLM-Research/Meta-Llama-3.1-8B-Instruct",
      "output_dir": "res/humaneval_Llama-3.1-8B-Instruct",
      "endpoint": "http://10.0.1.3:8080/common_evaluate_batch",
      "prompt_type": "llama-3-instruct",
      "temperature": 0,
      "top_p": 0.8,
      "top_k": 0,
      "min_p": 0,
      "max_completion_tokens": 32768,
      "n_sample": 1,
      "stop_token": "<|im_end|>",
      "num_gpus_total": 1,
      "num_gpus_per_model": 1,
      "reasoning_model": false
    }]
  }
}
  